import pandas as pd
import argparse
import os

# ä»»åŠ¡åˆ†ç±»å®šä¹‰
TASK_CATEGORIES = {
    "Single-Document QA": {
        "en": ["longbench_narrativeqa", "longbench_qasper", "longbench_multifieldqa_en"],
        "zh": ["longbench_multifieldqa_zh"]
    },
    "Multi-Document QA": {
        "en": ["longbench_hotpotqa", "longbench_2wikimqa", "longbench_musique"],
        "zh": ["longbench_dureader"]
    },
    "Summarization": {
        "en": ["longbench_gov_report", "longbench_qmsum", "longbench_multi_news"],
        "zh": ["longbench_vcsum"]
    },
    "Few-shot Learning": {
        "en": ["longbench_trec", "longbench_triviaqa", "longbench_samsum"],
        "zh": ["longbench_lsht"]
    },
    "Synthetic Tasks": {
        "en": ["longbench_passage_count", "longbench_passage_retrieval_en"],
        "zh": ["longbench_passage_retrieval_zh"]
    },
    "Code Completion": {
        "en": ["longbench_lcc", "longbench_repobench-p"],
        "zh": []
    }
}

def analyze(file_path, output_dir):
    df = pd.read_csv(file_path)

    # 1. æå–æ¯ä¸ªä»»åŠ¡çš„å¾—åˆ†
    task_scores = {}
    for col in df.columns:
        values = pd.to_numeric(df[col], errors='coerce').dropna()
        nonzero_values = values[values != 0]
        if not nonzero_values.empty:
            task_scores[col] = nonzero_values.iloc[0] * 100

    # 2. æ„å»ºè¯¦ç»†å¾—åˆ†æ•°æ®
    detailed_scores = []
    for category, langs in TASK_CATEGORIES.items():
        for lang, tasks in langs.items():
            for task in tasks:
                if task in task_scores:
                    detailed_scores.append((task, category, lang, round(task_scores[task], 1)))

    detailed_df = pd.DataFrame(detailed_scores, columns=["ä»»åŠ¡", "ä»»åŠ¡ç±»åˆ«", "è¯­è¨€", "å¾—åˆ†"])

    # 3. æ±‡æ€»å¹³å‡å€¼
    summary_results = []

    for category, langs in TASK_CATEGORIES.items():
        for lang, tasks in langs.items():
            scores = [task_scores[task] for task in tasks if task in task_scores]
            if scores:
                avg = sum(scores) / len(scores)
                summary_results.append((category, lang, "å¹³å‡å€¼", round(avg, 1)))

    # æ€»ä½“ç»Ÿè®¡
    en_scores = [score for _, _, lang, score in detailed_scores if lang == "en"]
    zh_scores = [score for _, _, lang, score in detailed_scores if lang == "zh"]
    all_scores = en_scores + zh_scores

    if en_scores:
        summary_results.append(("å…¨éƒ¨ä»»åŠ¡", "en", "å¹³å‡å€¼", round(sum(en_scores) / len(en_scores), 1)))
    if zh_scores:
        summary_results.append(("å…¨éƒ¨ä»»åŠ¡", "zh", "å¹³å‡å€¼", round(sum(zh_scores) / len(zh_scores), 1)))
    if all_scores:
        summary_results.append(("å…¨éƒ¨ä»»åŠ¡", "all", "å¹³å‡å€¼", round(sum(all_scores) / len(all_scores), 1)))


    summary_df = pd.DataFrame(summary_results, columns=["ä»»åŠ¡ç±»åˆ«", "è¯­è¨€", "è¯´æ˜", "å¹³å‡å¾—åˆ†"])

    # 4. è‡ªåŠ¨å‘½åå¹¶ä¿å­˜è¾“å‡º
    os.makedirs(output_dir, exist_ok=True)
    base_name = os.path.splitext(os.path.basename(file_path))[0]
    summary_path = os.path.join(output_dir, f"{base_name}_summary.csv")
    detail_path = os.path.join(output_dir, f"{base_name}_detail.csv")

    summary_df.to_csv(summary_path, index=False)
    detailed_df.to_csv(detail_path, index=False)

    print("âœ… åˆ†æå®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š")
    print(f" - ä»»åŠ¡æ±‡æ€»å¾—åˆ†ï¼š{summary_path}")
    print(f" - ä»»åŠ¡è¯¦ç»†å¾—åˆ†ï¼š{detail_path}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ğŸ“Š LongBench ä»»åŠ¡åˆ†æå·¥å…·")
    parser.add_argument("file", help="è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", default=".", help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰")
    args = parser.parse_args()

    analyze(args.file, args.output)
